
```{r}
.libPaths("/nas/longleaf/rhel8/apps/r/4.4.0/lib64/R/library")
library(magrittr)
library(ggplot2)
library(Seurat)
load('../so.RData')
options(future.globals.maxSize=5242880000)  
#this was needed to avoid an error about something being too large/above limits. This particular value is 5000*1024^2, based off of this page: https://stackoverflow.com/questions/40536067/how-to-adjust-future-global-maxsize-in-r
```

# Size-factor workflow

The standard size-factor workflow in Seurat involves two-steps. 
A size-factor normalization + log transformation step and then a scaling step. 

We first use `NormalizeData` to calculate size-factors, normalize, and do a log transformation.

From Seurat docs:
- “LogNormalize”: Feature counts for each cell are **divided by the total counts for that cell** and **multiplied by the scale.factor**. This is then **natural-log transformed** using log1p

The `scale.factor` argument is somewhat arbitrary number meant to bring normalized counts into the same order of magnitude as total counts/UMI per cell. Based on what we saw in our QC preprocessing our data were ~12k UMI per cell, so 10k would be an appropriate scale.factor. 

Notice we now have 4 more layers in our object after normalizing, these `data` layers have the normalized counts. 

```{r}
so.filtered <- NormalizeData(so.filtered, 
                             normalization.method = "LogNormalize", 
                             scale.factor = 10000) # the default scale.factor is 10000

Layers(so.filtered)
```

### Variable Features

The next step is to identify the most variable genes in the dataset. 

`FindVariableFeatures()` uses one of three available methods for identifying variable genes. 'vst' is the common choice, and uses polynomial regression. 

More details are here:
https://satijalab.org/seurat/reference/findvariablefeatures

In the case of a merged object with multiple layers (different samples) variable features are first identified in each layer separately. Then a shared set is identified between layers. If the shared set is smaller than the requested number of features, the list is suppplemented with additional features unique to each layer.

I cannot find clear documentation on this, but I believe the shared variable features are ranked by average variance across layers. 

https://github.com/satijalab/seurat/issues/8325


```{r}
so.filtered <- FindVariableFeatures(so.filtered,
                                    selection.method = "vst",
                                    nfeatures = 2000)

# we can use the VariableFeatures() function to access 
head(VariableFeatures(so.filtered), n = 50)
```

`VariableFeaturePlot()` is a useful confenience function to quickly plot variable features, with variance on the y-axis. 

```{r}
top10 <- head(VariableFeatures(so.filtered), 10)

plot1 <- VariableFeaturePlot(so.filtered)
LabelPoints(plot = plot1, points = top10, repel = TRUE, xnudge = 0, ynudge = 0) 
```

### Scaling


After normalizing it's standard to apply a linear transformation to scale the data.

This...
- shifts the counts for each gene so the mean counts of all genes = 0
- scales the counts so that that variance of for each gene across all cells = 1.

Since we have already identified variable features, `ScaleData()` will automatically only scale those features. 

This is because it is often recommended to use only the most variable genes for downstream steps like dimensionality reduction and clustering. The idea is to reduce the amount of "irrelevent" noise from more stable genes, which may make it harder to clearly separate clusters. The obvious downside is that if you are interested in certain genes that aren't highly variable then they won't be present in subsequent clustering steps (though they will for pseudobulk differential analysis.

The other benefit of only using variable features for scaling and downstream steps is that will have less data to juggle and things will run faster.

If we want to include all genes after we've identified variable features we can use the `features` argument to specify all genes or a custom subset if desired.

If we don't first find variable features then `ScaleData()` will by default scale all genes. 

--- 

When we scale the data we also have the option to "regress out" variables with the `vars.to.regress` argument.

"Regressing out" means removing the effect a variable has on gene expression. To do this Seurat fits a linear regression model to the data with the specified variable as a covariate. For each gene the effect of this covariate is subtracted to remove its effect.

It is common practice to "regress out" the effect of mitochondrial content, this is to prevent mitochondrial content from driving downstream analysis like clustering. **NOTE** that this assumes we don't care about the variability introduced by this variable, which may not be true for certain experiments / datasets.

After scaling the scaled data is added to a new slot called `scale.data` .

```{r}
so.filtered <- ScaleData(so.filtered, 
#          features = rownames(so.filtered),  # to scale using all genes 
          vars.to.regress = 'percent.mt' # to regress out mito percent, but slow
)
```

### Checking normalization

Let's take a look at how the normalization changed our counts.

Using  GAPDH as an example we see that before normalization the distribution of counts has a long tail. 

We also see that there's a strong positive correlation between total UMI and GAPDH counts 

As expected normalization gives us a more normal distribution and less of a correlation with sequencing depth. 

```{r}
gene_of_interest <- 'GAPDH'

so.filtered$'raw' <- so.filtered[['RNA']]$counts.PBMC_1[gene_of_interest,] 
so.filtered$'norm' <- so.filtered[['RNA']]$data.PBMC_1[gene_of_interest,] 
so.filtered$'scale' <- so.filtered[['RNA']]$scale.data[gene_of_interest,] 

#VlnPlot(so.filtered, features = 'MALAT1', slot = 'counts', pt.size = 0.2)

so.filtered@meta.data %>%
  ggplot(aes(raw)) +
  geom_histogram(bins = 50)

so.filtered@meta.data %>%
  ggplot(aes(nCount_RNA, raw)) +
  geom_point() +
  geom_density_2d()

#VlnPlot(so.filtered, features = 'MALAT1', slot = 'data', pt.size = 0.2)

so.filtered@meta.data %>%
  ggplot(aes(norm)) +
  geom_histogram(bins = 50)

so.filtered@meta.data %>%
  ggplot(aes(norm, nCount_RNA)) +
  geom_point() +
  geom_density_2d()

#so.filtered@meta.data %>%
#  ggplot(aes(gapdh_scale, nCount_RNA)) +
#  geom_point(alpha = 0.2) +
#  geom_density_2d() +
#  facet_wrap(~orig.ident)

```

Let's look at some of the most highly expressed genes... 

```{r}
topGenes <- rowSums(so.filtered[['RNA']]$data.PBMC_1) %>%
  sort(decreasing = T) %>%
  .[1:10]
topGenes
```

These normalizations don't look quite as good as they did for GAPDH. The distribution still doesn't look normal around 0 like we'd expect.

This is a rough example of why size-factor normalization doesn't seem to work well for all genes. 

```{r}
gene_of_interest <- 'EEF1A1'

so.filtered$'raw' <- so.filtered[['RNA']]$counts.PBMC_1[gene_of_interest,] 
so.filtered$'norm' <- so.filtered[['RNA']]$data.PBMC_1[gene_of_interest,] 
#so.filtered$'scale' <- so.filtered[['RNA']]$scale.data[gene_of_interest,] 

#VlnPlot(so.filtered, features = 'MALAT1', slot = 'counts', pt.size = 0.2)

so.filtered@meta.data %>%
  ggplot(aes(raw)) +
  geom_histogram(bins = 50)

so.filtered@meta.data %>%
  ggplot(aes(nCount_RNA, raw)) +
  geom_point() +
  geom_density_2d()

#VlnPlot(so.filtered, features = 'MALAT1', slot = 'data', pt.size = 0.2)

so.filtered@meta.data %>%
  ggplot(aes(norm)) +
  geom_histogram(bins = 50)

so.filtered@meta.data %>%
  ggplot(aes(norm, nCount_RNA)) +
  geom_point() +
  geom_density_2d()
```

## scTransform

While size-factor normalization does a decent job of controlling for differences in library size between cells, [Hafemeister and Satija, 2019](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1874-1) showed that highly expressed genes are not effectively normalized and exhibit distinct patterns.  

An alternative to size-factor normalization is to model the gene counts using a probability distribution. 

This gives us a per gene measure of average expression and variance, and thus avoids making assumptions across all cells / samples. 

The `sctransform` package from the Satija lab uses a **Regularized Negative Binomial Distribution** to model gene-wise counts across all cells. 

This approach may provide...
- better control of library size differences by modeling the relation of gene counts to total counts *per cell*
- improved handling of highly expressed and highly variable genes
- improved downstream dimensionality reduction and clustering 

Run the Seurat`SCTransform()` function on our merged object. By default each layer (sample) will be processed separately. 
As in the size-factor normalization workflow we can also specify variables to regress out if needed.

```{r}
# ~5m to run
so.filtered <- so.filtered %>%
  SCTransform(vst.flavor = 'v2', 
              verbose = T, 
              vars.to.regress = 'percent.mt',
              return.only.var.genes = T)
```

We set `vst.flavor = 'v2'` to specify some recent improvements. This automatically uses a tool for faster modeling `glmGamPoi`, but if you don't have this installed already `SCTransform()` will default to a different method and run much more slowly.

We also set `return.only.var.genes` to `FALSE`. `SCTransform` should be less susceptible to noise than standard workflow, so this is mostly a memory saving feature, and is `TRUE` by default.

After running `SCTransform()` we have a totally new assay in our Seurat Object called `SCT`.

You'll see it is set as the `Active assay` by default after running the transformation. 

```{r}
so.filtered
```
We have 3 layers in our `SCT` assay.
- counts -- these are library corrected (UMI corrected) counts
- data -- log transformed UMI corrected counts
- scale.data -- Pearson residuals from Negative binomial model

The `Pearson Residuals` are what are used for downstream steps like dimensionality reduction and clustering.

**NOTE** if you want to use the un-transformed data you either have to explicitly change assays with `DefaultAssay()` or pass an `assay` argument to the Seurat function you're using.

```{r}
DefaultAssay(so.filtered) <- 'RNA'

so.filtered
```



### Illustrating SCtransform

To quickly illustrate the rationale behind `SCtransform` let's look at the mean expression vs variance plot. 

When people started using probabilistic models for RNA-seq data the Poisson Distribution was a common choice. That's because the Poisson Distribution models **discrete events from a large pool of low probability**. Which sounds like RNA-seq. 

Here's a little simulation of data with a Poisson Distribution.

```{r}
# Set parameters for the simulation
n_genes <- 1000   # Number of genes
n_cells <- 200    # Number of cells

# Simulate mean expression levels for each gene (randomly chosen)
gene_means <- runif(n_genes, min = 0.1, max = 10)  # Mean expression per gene

# empty matrix of shape ngene x ncell
sim_poisson_counts <- matrix(0, nrow = n_genes, ncol = n_cells)

# loop ngenes and sample counts from a poisson distribution around the gene mean calc above
for (i in 1:n_genes) {
  sim_poisson_counts[i, ] <- rpois(n_cells, lambda = gene_means[i])  
}

# mean and variance per gene
gene_mean <- rowMeans(sim_poisson_counts)
gene_variance <- apply(sim_poisson_counts, 1, var)

# Plot the mean-variance relationship
data.frame(mean = gene_mean, 
           variance = gene_variance) %>%
  ggplot(aes(mean, variance)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed", size = 1) +
  scale_x_log10() +
  scale_y_log10() 
  
```

But biostatisticians realized that this model did not reflect the real distribution of RNA-seq data.

In this type of plot below a poisson distribution is a straight line. We can see that our data (and this is true generally of both bulk RNA and single cell data) sits above the poisson distribution. 

This is called "overdispersion" and indicates that the variance in our data is greater than the mean. 

The **Negative Binomial Distribution** is basically a poisson model with an extra parameter for variance, and much more accurately captures the shape of RNA-seq data.


```{r}
DefaultAssay(so.filtered) <- 'SCT'

raw_counts <- so.filtered[['RNA']]$counts.PBMC_1 %>%
  .[rownames(so.filtered[['SCT']]@SCTModel.list$PBMC_1@feature.attributes),]

gene_means <- rowMeans(raw_counts)  
gene_vars <- apply(raw_counts, 1, function(x) { mean(x^2) - mean(x)^2 })  
df <- data.frame(mean = gene_means, 
                 vars = gene_vars)

df %>%
  ggplot(aes(log(mean), log(vars))) +
  geom_point(alpha = 0.2) 

df %>%
  ggplot(aes(log(mean), log(vars))) +
  #geom_point(alpha = 0.2) +
  geom_hex(bins = 50 ) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  scale_fill_viridis_c() 
```

Here is a rough approximation of the the Negative Binomial Model would look like with our data. 

```{r}
#####
# approximation of the negative binomial
model<- lm(vars ~  1* mean + I(mean^2) + 0, data =df )
summary(model)

predicted_df<- data.frame(mean = df$mean,
                          var_predict = df$mean + model$coefficients[[1]] * (df$mean)^2 )

df %>%
  ggplot(aes(log10(mean), log10(vars))) +
#  geom_point(alpha = 0.2) +
  geom_hex(bins = 50 ) +
  geom_line(color = "red", 
            data = predicted_df, 
            aes(x = log10(gene_means), y =log10(var_predict))) +
  scale_fill_viridis_c() 

```

After `SCtransform` finds model parameters for each gene across our cells it calculates standarized `Pearson Residuals`.

Which is the difference between the observed counts in a gene to the predicted counts by the model (which is controlling primarily for library size). Thus the difference is the counts normalized to library. We just have a more flexible data-driven way of determining the gene-specific baseline for the normalization.

### SAVE!

```{r}
save(so.filtered, file = '../so.RData')
```


